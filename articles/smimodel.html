<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Introduction to smimodel • smimodel</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to smimodel">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">smimodel</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/smimodel.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/nuwani-palihawadana/smimodel/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Introduction to smimodel</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/nuwani-palihawadana/smimodel/blob/main/vignettes/smimodel.Rmd" class="external-link"><code>vignettes/smimodel.Rmd</code></a></small>
      <div class="d-none name"><code>smimodel.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="what-is-smimodel">What is smimodel?<a class="anchor" aria-label="anchor" href="#what-is-smimodel"></a>
</h2>
<p>The <em>smimodel</em> package provides functions to estimate
<strong>Sparse Multiple Index (SMI) Models</strong> for nonparametric
forecasting or prediction. To support time series forecasting, the
package functions are mainly build upon tidy temporal data in the
<code>tsibble</code> format. However, the SMI model formulation is very
general and does not exclusively depend on any temporal features. Hence,
the model can be used more widely – even with non-temporal
cross-sectional data. (In such case, a numeric <code>index</code>
(instead of a date or time related variable) can be used when
constructing the <code>tsibble</code>.)</p>
<p>The SMI Modelling algorithm (i.e. the estimation algorithm of SMI
model) that we implement here, simultaneously performs automatic
predictor selection (“sparse”) and predictor grouping, which is
especially useful in obtaining a parsimonious model in high-dimensional
contexts. For detailed information regarding the SMI model and the
estimation algorithm refer the related working paper at <a href="https://www.monash.edu/business/ebs/research/publications/ebs/2024/wp16-2024.pdf" class="external-link uri">https://www.monash.edu/business/ebs/research/publications/ebs/2024/wp16-2024.pdf</a>.</p>
</div>
<div class="section level2">
<h2 id="how-to-use-smimodel">How to use smimodel?<a class="anchor" aria-label="anchor" href="#how-to-use-smimodel"></a>
</h2>
<p>Here we present a simple example to illustrate <em>smimodel</em>
functionalities. We use randomly simualted data, which we treat as time
series data for the purpose of this illustration.</p>
<p>(Note: Since the SMI model estimation algorithm works with very
limited amount of prior information, and handles automatic predictor
selection and predictor grouping, the computational time for model
estimation increases as the number of predictors and the number of
indices increase. Therefore, we use a small simulated data set here as
the example to reduce computational cost.)</p>
<div class="section level3">
<h3 id="data-simulation">Data simulation<a class="anchor" aria-label="anchor" href="#data-simulation"></a>
</h3>
<p>Suppose we are interested in forecasting a response variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>,
which is an additive function of two nonlinear components involving five
predictor variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>_</mi><mn>000</mn><mo>,</mo><mi>x</mi><mi>_</mi><mn>001</mn><mo>,</mo><mi>x</mi><mi>_</mi><mn>002</mn><mo>,</mo><mi>x</mi><mi>_</mi><mn>003</mn></mrow><annotation encoding="application/x-tex">x\_000, x\_001, x\_002, x\_003</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>_</mi><mn>005</mn></mrow><annotation encoding="application/x-tex">x\_005</annotation></semantics></math>
plus a normally distributed white noise component. Here, the variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>_</mi><mn>001</mn><mo>,</mo><mi>x</mi><mi>_</mi><mn>002</mn><mo>,</mo><mi>x</mi><mi>_</mi><mn>003</mn></mrow><annotation encoding="application/x-tex">x\_001, x\_002, x\_003</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>_</mi><mn>005</mn></mrow><annotation encoding="application/x-tex">x\_005</annotation></semantics></math>
correspond to the first, second, third and fifth lags of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>_</mi><mn>000</mn></mrow><annotation encoding="application/x-tex">x\_000</annotation></semantics></math>
respectively.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Load required packages </span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/nuwani-palihawadana/smimodel" class="external-link">smimodel</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://roi.r-forge.r-project.org/" class="external-link">ROI</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tibble.tidyverse.org/" class="external-link">tibble</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org" class="external-link">tidyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tsibble.tidyverts.org" class="external-link">tsibble</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Simulate data</span></span>
<span></span>
<span><span class="co"># Length of the time series</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1405</span> </span>
<span></span>
<span><span class="co"># Set a seed for reproduciblity</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate data</span></span>
<span><span class="va">sim_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>x_000 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span></span>
<span>    <span class="co"># Add x_lags</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="../reference/lag_matrix.html">lag_matrix</a></span><span class="op">(</span><span class="va">x_000</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pack.html" class="external-link">unpack</a></span><span class="op">(</span><span class="va">x</span>, names_sep <span class="op">=</span> <span class="st">"_"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span></span>
<span>    <span class="co"># Response variable</span></span>
<span>    y <span class="op">=</span> <span class="op">(</span><span class="fl">0.9</span><span class="op">*</span><span class="va">x_000</span> <span class="op">+</span> <span class="fl">0.6</span><span class="op">*</span><span class="va">x_001</span> <span class="op">+</span> <span class="fl">0.45</span><span class="op">*</span><span class="va">x_003</span><span class="op">)</span><span class="op">^</span><span class="fl">3</span> <span class="op">+</span> </span>
<span>      <span class="op">(</span><span class="fl">0.35</span><span class="op">*</span><span class="va">x_002</span> <span class="op">+</span> <span class="fl">0.7</span><span class="op">*</span><span class="va">x_005</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span>, sd <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>,</span>
<span>    <span class="co"># Add an index to the data set</span></span>
<span>    inddd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/drop_na.html" class="external-link">drop_na</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">inddd</span>, <span class="va">y</span>, <span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html" class="external-link">starts_with</a></span><span class="op">(</span><span class="st">"x_"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="co"># Make the data set a `tsibble`</span></span>
<span>  <span class="fu"><a href="https://tsibble.tidyverts.org/reference/as-tsibble.html" class="external-link">as_tsibble</a></span><span class="op">(</span>index <span class="op">=</span> <span class="va">inddd</span><span class="op">)</span></span></code></pre></div>
<p>Note that here we create an additional <code>numeric</code> variable
<code>inddd</code> to serve as the <code>index</code> of the data set,
when we convert the data set into an object of class
<code>tsibble</code>.</p>
<p>Next, we split the data into training and test sets so that the
models can be estimated using the training data set, and the fitted
models can be evaluated on the predictions obtained for the test set,
which is not used for model estimation.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Data Split</span></span>
<span></span>
<span><span class="co"># Training set</span></span>
<span><span class="va">sim_train</span> <span class="op">&lt;-</span> <span class="va">sim_data</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">1200</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># Test set</span></span>
<span><span class="va">sim_test</span> <span class="op">&lt;-</span> <span class="va">sim_data</span><span class="op">[</span><span class="fl">1201</span><span class="op">:</span><span class="fl">1400</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># Here, we sequentially split the data as we assume time series data. </span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="smi-model-estimation">SMI model estimation<a class="anchor" aria-label="anchor" href="#smi-model-estimation"></a>
</h3>
<p>We first train SMI models on the training set using three different
initialisation options “ppr”, “additive” and “linear” for comparison
purposes. Please refer to package documentation/working paper for more
information regarding available initialisation options.</p>
<p>(Note: The choice of the initialisation largely depends on the data
and application. Thus, users are encouraged to follow a trial-and-error
procedure to determine the most suitable initial model for a given
application.)</p>
<p>Here, we assume that we do not have any prior knowledge about the
construction of the response variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>.
Hence, we input
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>_</mi><mn>000</mn></mrow><annotation encoding="application/x-tex">x\_000</annotation></semantics></math>
and its first five lags as our predictor variables into the estimation
algorithm, as predictors which are entering indices.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Index variables</span></span>
<span><span class="va">index.vars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">sim_data</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">8</span><span class="op">]</span></span></code></pre></div>
<div class="section level4">
<h4 id="smi-model-with-ppr-initialisation">SMI model with “ppr” initialisation:<a class="anchor" aria-label="anchor" href="#smi-model-with-ppr-initialisation"></a>
</h4>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## SMI model with "PPR" initialisation</span></span>
<span><span class="va">smimodel_ppr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/model_smimodel.html">model_smimodel</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">sim_train</span>,</span>
<span>                               yvar <span class="op">=</span> <span class="st">"y"</span>,</span>
<span>                               index.vars <span class="op">=</span> <span class="va">index.vars</span>,</span>
<span>                               initialise <span class="op">=</span> <span class="st">"ppr"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "model 1"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fitted optimal SMI model</span></span>
<span><span class="va">smimodel_ppr</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">best</span></span>
<span><span class="co">#&gt; $alpha</span></span>
<span><span class="co">#&gt; 6 x 2 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;          index1   index2</span></span>
<span><span class="co">#&gt; x_000 1.6279857 .       </span></span>
<span><span class="co">#&gt; x_001 1.0728102 .       </span></span>
<span><span class="co">#&gt; x_002 .         1.211800</span></span>
<span><span class="co">#&gt; x_003 0.8107054 .       </span></span>
<span><span class="co">#&gt; x_004 .         .       </span></span>
<span><span class="co">#&gt; x_005 .         2.298439</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $derivatives</span></span>
<span><span class="co">#&gt; # A tibble: 1,200 × 2</span></span>
<span><span class="co">#&gt;       d1    d2</span></span>
<span><span class="co">#&gt;    &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span><span class="co">#&gt;  1 0.973 0.387</span></span>
<span><span class="co">#&gt;  2 1.41  0.550</span></span>
<span><span class="co">#&gt;  3 4.06  0.190</span></span>
<span><span class="co">#&gt;  4 1.74  0.460</span></span>
<span><span class="co">#&gt;  5 1.62  0.603</span></span>
<span><span class="co">#&gt;  6 4.04  0.159</span></span>
<span><span class="co">#&gt;  7 2.60  0.390</span></span>
<span><span class="co">#&gt;  8 1.90  0.599</span></span>
<span><span class="co">#&gt;  9 2.89  0.387</span></span>
<span><span class="co">#&gt; 10 0.777 0.375</span></span>
<span><span class="co">#&gt; # ℹ 1,190 more rows</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $var_y</span></span>
<span><span class="co">#&gt; [1] "y"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_index</span></span>
<span><span class="co">#&gt; [1] "x_000" "x_001" "x_002" "x_003" "x_004" "x_005"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_s</span></span>
<span><span class="co">#&gt; NULL</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_linear</span></span>
<span><span class="co">#&gt; NULL</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $neighbour</span></span>
<span><span class="co">#&gt; [1] 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $gam</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: gaussian </span></span>
<span><span class="co">#&gt; Link function: identity </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(index1, bs = "cr") + s(index2, bs = "cr")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Estimated degrees of freedom:</span></span>
<span><span class="co">#&gt; 8.5 6.1  total = 15.6 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; REML score: -1028.854     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"class")</span></span>
<span><span class="co">#&gt; [1] "smimodelFit" "list"</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Estimated index structure</span></span>
<span><span class="va">smimodel_ppr</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">best</span><span class="op">$</span><span class="va">alpha</span></span>
<span><span class="co">#&gt; 6 x 2 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;          index1   index2</span></span>
<span><span class="co">#&gt; x_000 1.6279857 .       </span></span>
<span><span class="co">#&gt; x_001 1.0728102 .       </span></span>
<span><span class="co">#&gt; x_002 .         1.211800</span></span>
<span><span class="co">#&gt; x_003 0.8107054 .       </span></span>
<span><span class="co">#&gt; x_004 .         .       </span></span>
<span><span class="co">#&gt; x_005 .         2.298439</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="smi-model-with-additive-initialisation">SMI model with “additive” initialisation:<a class="anchor" aria-label="anchor" href="#smi-model-with-additive-initialisation"></a>
</h4>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## SMI model with "Additive" initialisation</span></span>
<span><span class="va">smimodel_additive</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/model_smimodel.html">model_smimodel</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">sim_train</span>,</span>
<span>                                    yvar <span class="op">=</span> <span class="st">"y"</span>,</span>
<span>                                    index.vars <span class="op">=</span> <span class="va">index.vars</span>,</span>
<span>                                    initialise <span class="op">=</span> <span class="st">"additive"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "model 1"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fitted optimal SMI model</span></span>
<span><span class="va">smimodel_additive</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">best</span></span>
<span><span class="co">#&gt; $alpha</span></span>
<span><span class="co">#&gt; 6 x 2 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;          index1    index2</span></span>
<span><span class="co">#&gt; x_000 0.4634955 .        </span></span>
<span><span class="co">#&gt; x_001 0.3054954 .        </span></span>
<span><span class="co">#&gt; x_002 .         0.3451773</span></span>
<span><span class="co">#&gt; x_003 0.2310091 .        </span></span>
<span><span class="co">#&gt; x_004 .         .        </span></span>
<span><span class="co">#&gt; x_005 .         0.6548227</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $derivatives</span></span>
<span><span class="co">#&gt; # A tibble: 1,200 × 2</span></span>
<span><span class="co">#&gt;       d1    d2</span></span>
<span><span class="co">#&gt;    &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span><span class="co">#&gt;  1  3.42 1.36 </span></span>
<span><span class="co">#&gt;  2  4.95 1.93 </span></span>
<span><span class="co">#&gt;  3 14.3  0.667</span></span>
<span><span class="co">#&gt;  4  6.12 1.62 </span></span>
<span><span class="co">#&gt;  5  5.69 2.12 </span></span>
<span><span class="co">#&gt;  6 14.2  0.559</span></span>
<span><span class="co">#&gt;  7  9.14 1.37 </span></span>
<span><span class="co">#&gt;  8  6.69 2.10 </span></span>
<span><span class="co">#&gt;  9 10.1  1.36 </span></span>
<span><span class="co">#&gt; 10  2.73 1.31 </span></span>
<span><span class="co">#&gt; # ℹ 1,190 more rows</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $var_y</span></span>
<span><span class="co">#&gt; [1] "y"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_index</span></span>
<span><span class="co">#&gt; [1] "x_000" "x_001" "x_002" "x_003" "x_004" "x_005"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_s</span></span>
<span><span class="co">#&gt; NULL</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_linear</span></span>
<span><span class="co">#&gt; NULL</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $neighbour</span></span>
<span><span class="co">#&gt; [1] 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $gam</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: gaussian </span></span>
<span><span class="co">#&gt; Link function: identity </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(index1, bs = "cr") + s(index2, bs = "cr")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Estimated degrees of freedom:</span></span>
<span><span class="co">#&gt; 8.50 6.09  total = 15.59 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; REML score: -1028.856     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"class")</span></span>
<span><span class="co">#&gt; [1] "smimodelFit" "list"</span></span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Estimated index structure</span></span>
<span><span class="va">smimodel_additive</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">best</span><span class="op">$</span><span class="va">alpha</span></span>
<span><span class="co">#&gt; 6 x 2 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;          index1    index2</span></span>
<span><span class="co">#&gt; x_000 0.4634955 .        </span></span>
<span><span class="co">#&gt; x_001 0.3054954 .        </span></span>
<span><span class="co">#&gt; x_002 .         0.3451773</span></span>
<span><span class="co">#&gt; x_003 0.2310091 .        </span></span>
<span><span class="co">#&gt; x_004 .         .        </span></span>
<span><span class="co">#&gt; x_005 .         0.6548227</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="smi-model-with-linear-initialisation">SMI model with “linear” initialisation:<a class="anchor" aria-label="anchor" href="#smi-model-with-linear-initialisation"></a>
</h4>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## SMI model with "Linear" initialisation</span></span>
<span><span class="va">smimodel_linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/model_smimodel.html">model_smimodel</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">sim_train</span>,</span>
<span>                                  yvar <span class="op">=</span> <span class="st">"y"</span>,</span>
<span>                                  index.vars <span class="op">=</span> <span class="va">index.vars</span>,</span>
<span>                                  initialise <span class="op">=</span> <span class="st">"linear"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "model 1"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fitted optimal SMI model</span></span>
<span><span class="va">smimodel_linear</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">best</span></span>
<span><span class="co">#&gt; $alpha</span></span>
<span><span class="co">#&gt; 6 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;           index1</span></span>
<span><span class="co">#&gt; x_000 0.40811741</span></span>
<span><span class="co">#&gt; x_001 0.26853838</span></span>
<span><span class="co">#&gt; x_002 0.04185720</span></span>
<span><span class="co">#&gt; x_003 0.20411136</span></span>
<span><span class="co">#&gt; x_004 .         </span></span>
<span><span class="co">#&gt; x_005 0.07737565</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $derivatives</span></span>
<span><span class="co">#&gt; # A tibble: 1,200 × 1</span></span>
<span><span class="co">#&gt;       d1</span></span>
<span><span class="co">#&gt;    &lt;dbl&gt;</span></span>
<span><span class="co">#&gt;  1  4.35</span></span>
<span><span class="co">#&gt;  2  6.55</span></span>
<span><span class="co">#&gt;  3 14.4 </span></span>
<span><span class="co">#&gt;  4  8.30</span></span>
<span><span class="co">#&gt;  5  7.70</span></span>
<span><span class="co">#&gt;  6 14.0 </span></span>
<span><span class="co">#&gt;  7 10.3 </span></span>
<span><span class="co">#&gt;  8  9.97</span></span>
<span><span class="co">#&gt;  9 11.8 </span></span>
<span><span class="co">#&gt; 10  3.27</span></span>
<span><span class="co">#&gt; # ℹ 1,190 more rows</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $var_y</span></span>
<span><span class="co">#&gt; [1] "y"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_index</span></span>
<span><span class="co">#&gt; [1] "x_000" "x_001" "x_002" "x_003" "x_004" "x_005"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_s</span></span>
<span><span class="co">#&gt; NULL</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_linear</span></span>
<span><span class="co">#&gt; NULL</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $neighbour</span></span>
<span><span class="co">#&gt; [1] 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $gam</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: gaussian </span></span>
<span><span class="co">#&gt; Link function: identity </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(index1, bs = "cr")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Estimated degrees of freedom:</span></span>
<span><span class="co">#&gt; 7.8  total = 8.8 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; REML score: -445.1356     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"class")</span></span>
<span><span class="co">#&gt; [1] "smimodelFit" "list"</span></span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Estimated index structure</span></span>
<span><span class="va">smimodel_linear</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">best</span><span class="op">$</span><span class="va">alpha</span></span>
<span><span class="co">#&gt; 6 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;           index1</span></span>
<span><span class="co">#&gt; x_000 0.40811741</span></span>
<span><span class="co">#&gt; x_001 0.26853838</span></span>
<span><span class="co">#&gt; x_002 0.04185720</span></span>
<span><span class="co">#&gt; x_003 0.20411136</span></span>
<span><span class="co">#&gt; x_004 .         </span></span>
<span><span class="co">#&gt; x_005 0.07737565</span></span></code></pre></div>
<p>In this case, the SMI models fitted with “ppr” and “additive”
initialisation options have correctly identified the index structure of
the response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
by estimating two linear combinations (i.e. indices), while dropping out
the irrelevant predictor
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>_</mi><mn>004</mn></mrow><annotation encoding="application/x-tex">x\_004</annotation></semantics></math>.
While correctly identifying
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>_</mi><mn>004</mn></mrow><annotation encoding="application/x-tex">x\_004</annotation></semantics></math>
as an irrelevant predictor variable, the SMI model estimated with
“linear” intialisation however, has not correctly identified the index
structure of the model – has estimated only a single index instead of
the two indices.</p>
<p>Thus, as mentioned earlier, the final estimated model can change
depending on the initialisation option chosen. Hence, the users are
encouraged to experiment with different available initialisation options
when choosing the best fit for the data/application of interest. (In a
real-world problem (where the true model is unknown), it will be useful
to fit SMI models with different initialisation options, and see which
option gives the best forecasting/prediction accuracy.)</p>
</div>
</div>
<div class="section level3">
<h3 id="visualisation-of-estimated-smooths">Visualisation of estimated smooths<a class="anchor" aria-label="anchor" href="#visualisation-of-estimated-smooths"></a>
</h3>
<p>Once you fit a SMI model, the partial effects of the estimated
smooths corresponding to the estimated indices can be plotted using the
<code>autoplot</code> method as below.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Plot estimated smooths of the SMI model with "ppr" initialisation</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html" class="external-link">autoplot</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">smimodel_ppr</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="figure/autoplot-1.png" alt="plot of chunk autoplot"><div class="figcaption">plot of chunk autoplot</div>
</div>
</div>
<div class="section level3">
<h3 id="residuals-and-fitted-values">Residuals and fitted values<a class="anchor" aria-label="anchor" href="#residuals-and-fitted-values"></a>
</h3>
<p>We can use the <code>augment</code> method to obtain the residuals
and the fitted values from an estimated SMI model.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Obtain residuals and fitted values</span></span>
<span><span class="fu"><a href="https://generics.r-lib.org/reference/augment.html" class="external-link">augment</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">smimodel_ppr</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 1,200 × 3</span></span>
<span><span class="co">#&gt;    Index   .resid .fitted</span></span>
<span><span class="co">#&gt;    &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span><span class="co">#&gt;  1     6  0.0566    0.757</span></span>
<span><span class="co">#&gt;  2     7 -0.0397    1.50 </span></span>
<span><span class="co">#&gt;  3     8 -0.0552    3.78 </span></span>
<span><span class="co">#&gt;  4     9  0.0499    1.78 </span></span>
<span><span class="co">#&gt;  5    10  0.155     1.88 </span></span>
<span><span class="co">#&gt;  6    11 -0.145     3.70 </span></span>
<span><span class="co">#&gt;  7    12  0.200     2.16 </span></span>
<span><span class="co">#&gt;  8    13 -0.00571   2.20 </span></span>
<span><span class="co">#&gt;  9    14 -0.0585    2.78 </span></span>
<span><span class="co">#&gt; 10    15  0.0690    0.588</span></span>
<span><span class="co">#&gt; # ℹ 1,190 more rows</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="forecasts-on-a-test-set">Forecasts on a test set<a class="anchor" aria-label="anchor" href="#forecasts-on-a-test-set"></a>
</h3>
<p>Based on an estimated SMI model, we obtain forecasts/predictions on a
test set as below, using the <code>predict</code> method.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Obtain forecasts on the test set</span></span>
<span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">smimodel_ppr</span>, newdata <span class="op">=</span> <span class="va">sim_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in meanf(object, h = h, level = level, fan = fan, lambda = lambda, : unused argument (newdata = list(1206:1405, c(3.49124169545011, 1.48362868456093, 0.502781151466303, 2.27193619962515, 1.14531957808155, 1.45610984085034, 3.44879723658308, 1.21856507692158, 1.21510637841818, 0.777318678622333, 1.13879005345479, 1.55195753203221, 1.19285369023581, 1.26592393873102, 1.53103764698884, 2.37005214231825, 0.78447230639341, 1.19430266360755, 1.08636567330945, 4.61157154321595, 0.470003649662609, 1.01924959240427, 0.883525899157584, 1.43646535084252, 2.41344470602436, 0.210141931929313, </span></span>
<span><span class="co">#&gt; 0.637251369935488, 0.48483017070957, 0.967151385758648, 0.540051693859614, -0.00591690534489676, 0.192829269886108, 0.687094548337608, 2.23704857017094, 0.972787800623502, 0.248468455796017, 0.446560560518275, 0.937642573921337, 1.07642135846068, 1.36846596926693, 1.1095286857625, 0.842464729814123, 0.630526633304537, 0.181361282139659, 1.39781262875024, 1.76451132929887, 1.65183991960776, 1.67212413073567, 0.510996840980813, 0.340838317973449, 1.7758057963399, 0.182496225707728, 0.765780887805571, </span></span>
<span><span class="co">#&gt; 2.87258591205838, 1.41653317072242, 1.21698679549925, 1.58445535932184, 0.456804606298418, 0.948892290643738, 0.782124436629586, 0.269516644409916, 0.564125078993966, 3.67479247159151, 0.249428593046589, 2.41414442388989, 1.1151045093036, 1.18091880331075, 2.48594504621317, 0.8366968619727, 3.62113303953107, 1.85194307899537, 2.55369432217125, 2.88924298012293, 1.21559903430533, 1.39883053317104, 0.357327249260404, 1.41962608127244, 1.96885399110918, 1.85271563305469, 2.74894999933475, 0.848028509082333, </span></span>
<span><span class="co">#&gt; 2.4123314000411, 1.95653420413829, 1.09935402928691, 1.24013561056973, 2.45910901240064, 1.86299612209842, 0.779584087472622, 2.09700154359553, 1.66581902624261, 0.849626097247215, 2.28158752445974, 2.18492647368283, 3.20300505719549, 2.88106799282498, 0.484330876375508, 0.879319320585379, 1.57017242078446, 2.08452300185845, 2.88952363358089, 1.90686097300448, 0.883656221683908, 0.427785135368411, 1.29809079449427, 0.462613933115877, 0.49111505664609, 0.472619554531524, 1.15215841506567, 0.889414767405721, </span></span>
<span><span class="co">#&gt; 0.997940424282521, 0.924419182096793, 0.992723113163425, 1.48599353487017, 0.552356378895732, 0.696160627938453, 0.56078848349202, 1.32881657641147, 1.44532143106875, 2.15143239251275, 1.99329991511979, 2.9653679860765, 0.806993063267065, 2.2397432320482, 0.203333035586841, 1.1885383715076, 1.34081109537064, 0.478576008768312, 1.27662766619159, 1.5084639051408, 1.06419969381383, 0.879954928978607, 1.3197077558515, 2.44087718061084, 2.40808377207946, 2.66875800605847, 1.09906425009879, 1.44237266345647, </span></span>
<span><span class="co">#&gt; 1.08049007302439, 0.71776262976184, 0.934254863606583, 3.00845994344627, 1.33170081065305, 1.55531353894963, 2.17088609304485, 1.74388974176988, 1.00039187818363, 0.244443383064422, 0.363092362386087, 0.108011716088827, 0.241389845688585, 0.123337892716965, 0.111588462436474, 0.899819657518003, 0.888271389531245, 0.385985761505963, 2.2435527237008, 0.441588283874196, 1.67982534140622, 1.71940589840161, 0.713374843791116, 0.538975431559374, 0.123878832171816, 0.957385207634123, 0.415557958390278, </span></span>
<span><span class="co">#&gt; 0.0796062394100005, 0.431013040324381, 0.038154833257998, 0.346458009662973, 0.660795831115044, 1.37469317700219, 2.60824644866285, 1.51871231915771, 3.17827515485932, 1.07891489715191, 0.997401093188051, 2.04560480378541, 0.437245201396994, 3.02189977021293, 0.653553937464913, 1.45339620156137, 1.50243841013214, 0.241936790268776, 2.61481425058869, 0.369841510025043, 0.998178525980495, 2.89159786476145, 1.7430900805267, 1.7096876262859, 1.26646771472005, 1.02338041495689, 2.23273213146023, 2.46246871305876, </span></span>
<span><span class="co">#&gt; 1.44666530331206, 0.406412247646625, 0.397387842614919, 0.525586144889597, 0.449129836713747, 0.0306210066043653, 0.312672444538681, 0.276866814666007), c(0.988708860939369, 0.0647511295974255, 0.157662777928635, 0.785348618403077, 0.542188289808109, 0.416547345230356, 0.998882649000734, 0.255673117004335, 0.507875671144575, 0.0789711775723845, 0.813668364426121, 0.38217916013673, 0.802182707935572, 0.197923636762425, 0.946399770211428, 0.345672474242747, 0.522050247294828, 0.111688006436452, 0.885974851204082, </span></span>
<span><span class="co">#&gt; 0.95425497321412, 0.0403807631228119, 0.4936161886435, 0.226063704816625, 0.858800339279696, 0.53093573381193, 0.0046381508000195, 0.277560080168769, 0.325203143060207, 0.588706276612356, 0.249684700742364, 0.0431172808166593, 0.110678787576035, 0.703753812005743, 0.939021238824353, 0.311169018037617, 0.0784929301589727, 0.321744091343135, 0.624905536882579, 0.440241849515587, 0.801345300627872, 0.279283805051818, 0.570713193388656, 0.0421280120499432, 0.190717455465347, 0.727086470695212, 0.826690050307661, </span></span>
<span><span class="co">#&gt; 0.510721075348556, 0.567726165754721, 0.00115581974387169, 0.143778103170916, 0.865967083023861, 0.0825610605534166, 0.244570682058111, 0.98154315748252, 0.57758127944544, 0.24872636445798, 0.614953953772783, 0.0317573207430542, 0.146423544269055, 0.703072973992676, 0.065560708520934, 0.621807062299922, 0.937327365390956, 0.0878946147859097, 0.972803509328514, 0.0260107105132192, 0.725227952003479, 0.453706391621381, 0.566182404989377, 0.87273104628548, 0.55456317961216, 0.737652207259089, 0.62312916200608, </span></span>
<span><span class="co">#&gt; 0.311028405791149, 0.392196484608576, 0.202087455429137, 0.852780389599502, 0.606830150820315, 0.75609801383689, 0.562516808742657, 0.275899012805894, 0.735558403655887, 0.549279793864116, 0.346127043943852, 0.514965634793043, 0.815767947584391, 0.526272569317371, 0.203040049877018, 0.848107680445537, 0.370494215050712, 0.303325170883909, 0.770597046939656, 0.733448554994538, 0.838905998272821, 0.569048842415214, 0.02628083829768, 0.486127228243276, 0.542681032791734, 0.836660116910934, 0.728664538124576, </span></span>
<span><span class="co">#&gt; 0.555113806854934, 0.0734143974259496, 0.136502299224958, 0.684608696261421, 0.0996219362132251, 0.203785905148834, 0.365980138303712, 0.846195757621899, 0.236872595502064, 0.704877850599587, 0.107608830789104, 0.779068868607283, 0.25510568334721, 0.548043326009065, 0.0339015207719058, 0.806109476136044, 0.337752807186916, 0.916285858023912, 0.357106417883188, 0.975365013116971, 0.384378522634506, 0.488673535175622, 0.490776231279597, 0.0122546241618693, 0.641473200637847, 0.512574971653521, 0.320352118229493, </span></span>
<span><span class="co">#&gt; 0.58143315766938, 0.617344408296049, 0.438274537678808, 0.170368980616331, 0.71508049662225, 0.747786548687145, 0.843914708122611, 0.534759046975523, 0.302235261537135, 0.456518182065338, 0.384342534467578, 0.249046854674816, 0.654626744799316, 0.95532370172441, 0.291082957293838, 0.650189086562023, 0.536359930876642, 0.597451866604388, 0.0248982694465667, 0.00484173954464495, 0.131378254387528, 0.0248171037528664, 0.0921294519212097, 0.475558224134147, 0.196656761225313, 0.814673948567361, 0.244059228105471, </span></span>
<span><span class="co">#&gt; 0.488807637942955, 0.648882479639724, 0.158716470003128, 0.836977910948917, 0.436596529791132, 0.233495525084436, 0.298855992034078, 0.159421336837113, 0.585567104164511, 0.14877797709778, 0.179059559712186, 0.339221504982561, 0.18390193884261, 0.405541522195563, 0.613559618359432, 0.685671334387735, 0.823525600135326, 0.373982113786042, 0.952841004589573, 0.0188321589957923, 0.61237497231923, 0.463573763845488, 0.354729620506987, 0.882423028815538, 0.075802858453244, 0.88329119165428, 0.188221835764125, </span></span>
<span><span class="co">#&gt; 0.215066746808589, 0.869532291544601, 0.0608380562625825, 0.234899600734934, 0.993015512824059, 0.678197727771476, 0.435486800502986, 0.37730994191952, 0.46118402434513, 0.801851871656254, 0.662966975243762, 0.46600366407074, 0.053259436506778, 0.23719791835174, 0.233239737572148, 0.230653600767255, 0.0617262739688158, 0.497118609258905, 0.24412508867681), c(0.486705572577193, 0.988708860939369, 0.0647511295974255, 0.157662777928635, 0.785348618403077, 0.542188289808109, 0.416547345230356, 0.998882649000734, </span></span>
<span><span class="co">#&gt; 0.255673117004335, 0.507875671144575, 0.0789711775723845, 0.813668364426121, 0.38217916013673, 0.802182707935572, 0.197923636762425, 0.946399770211428, 0.345672474242747, 0.522050247294828, 0.111688006436452, 0.885974851204082, 0.95425497321412, 0.0403807631228119, 0.4936161886435, 0.226063704816625, 0.858800339279696, 0.53093573381193, 0.0046381508000195, 0.277560080168769, 0.325203143060207, 0.588706276612356, 0.249684700742364, 0.0431172808166593, 0.110678787576035, 0.703753812005743, 0.939</span></span>
<span><span class="va">preds</span><span class="op">$</span><span class="va">.predict</span></span>
<span><span class="co">#&gt; Error: object 'preds' not found</span></span></code></pre></div>
<p>Once we obtain forecasts/predictions, we can evaluate the
forecasting/predictive performance of the estimated SMI model by
calculating forecast/prediction error measurements as desired.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Calculate test set MSE and MAE</span></span>
<span><span class="va">MSE_SMI_ppr</span> <span class="op">=</span> <span class="fu"><a href="../reference/point_measures.html">MSE</a></span><span class="op">(</span>residuals <span class="op">=</span> <span class="op">(</span><span class="va">preds</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="va">preds</span><span class="op">$</span><span class="va">.predict</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error: object 'preds' not found</span></span>
<span><span class="va">MSE_SMI_ppr</span></span>
<span><span class="co">#&gt; Error: object 'MSE_SMI_ppr' not found</span></span>
<span><span class="va">MAE_SMI_ppr</span> <span class="op">=</span> <span class="fu"><a href="../reference/point_measures.html">MAE</a></span><span class="op">(</span>residuals <span class="op">=</span> <span class="op">(</span><span class="va">preds</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="va">preds</span><span class="op">$</span><span class="va">.predict</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error: object 'preds' not found</span></span>
<span><span class="va">MAE_SMI_ppr</span></span>
<span><span class="co">#&gt; Error: object 'MAE_SMI_ppr' not found</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="tuning-for-penalty-parameters">Tuning for penalty parameters<a class="anchor" aria-label="anchor" href="#tuning-for-penalty-parameters"></a>
</h3>
<p>The estimation of a SMI model involves solving an optimaisation
problem, where the sum of squared errors of the model plus two penalty
terms (an L0 penalty and an L2 (ridge) penalty) is minimised subject to
a set of constraints (please refer the working paper for details). Thus,
two penalty parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>λ</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\lambda_{0}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>λ</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\lambda_{2}</annotation></semantics></math>
corresponding to the L0 and L2 penalties respectively should be chosen
when estimating a SMI model.</p>
<p>In the previous example, all the SMI models were fitted using the
default penalty parameter values provided in the function:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\lambda_{0} = 1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mn>2</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\lambda_{2} = 1</annotation></semantics></math>.
To fit a SMI model with simultaneous parameter tuning, we can use the
function <code><a href="../reference/greedy_smimodel.html">greedy_smimodel()</a></code>, which performs a greedy search
over a given grid of penalty parameter combinations
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>λ</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\lambda_{0}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>λ</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\lambda_{2}</annotation></semantics></math>),
and fits the SMI model using the best (lowest validation set MSE)
penalty parameter combination. In this case, we need to provide a
validation set, which is separate from the training data set.</p>
<p>Therefore, let’s split our original training set in the above example
into two parts again to obtain a validation set.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># New training set</span></span>
<span><span class="va">sim_train_new</span> <span class="op">&lt;-</span> <span class="va">sim_data</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">1000</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># Validation set</span></span>
<span><span class="va">sim_val_new</span> <span class="op">&lt;-</span> <span class="va">sim_data</span><span class="op">[</span><span class="fl">1001</span><span class="op">:</span><span class="fl">1200</span>, <span class="op">]</span></span></code></pre></div>
<p>Next, we can estimate the SMI model with simultaneous penalty
parameter tuning as follows. Here, we use the initialisation option
“ppr” just to demonstrate the functionality.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Estimating SMI model with penalty parameter tuning</span></span>
<span><span class="va">smimodel_ppr_tune</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/greedy_smimodel.html">greedy_smimodel</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">sim_train_new</span>, </span>
<span>                                     val.data <span class="op">=</span> <span class="va">sim_val_new</span>,</span>
<span>                                     yvar <span class="op">=</span> <span class="st">"y"</span>,</span>
<span>                                     index.vars <span class="op">=</span> <span class="va">index.vars</span>,</span>
<span>                                     initialise <span class="op">=</span> <span class="st">"ppr"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "model 1"</span></span>
<span><span class="co">#&gt; [1] "model 1"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Potential starting points completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 1 completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 2 completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 3 completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Maximum iterations reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 4 completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 5 completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 6 completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 7 completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 8 completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Initial search around potential starting point 9 completed."</span></span>
<span><span class="co">#&gt; [1] "Starting point for the greedy search selected."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "An iteration of greedy search - step 1 is completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "An iteration of greedy search - step 1 is completed."</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Loss increased for 3 consecutive iterations!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "An iteration of greedy search - step 1 is completed."</span></span>
<span><span class="co">#&gt; [1] "Maximum iterations reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Tolerance for loss reached!"</span></span>
<span><span class="co">#&gt; [1] "Final model fitted!"</span></span>
<span><span class="co">#&gt; [1] "Final SMI model is fitted."</span></span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fitted optimal SMI model</span></span>
<span><span class="va">smimodel_ppr_tune</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">best</span></span>
<span><span class="co">#&gt; $alpha</span></span>
<span><span class="co">#&gt; 6 x 2 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;          index1   index2</span></span>
<span><span class="co">#&gt; x_000 1.6282120 .       </span></span>
<span><span class="co">#&gt; x_001 1.0726790 .       </span></span>
<span><span class="co">#&gt; x_002 .         1.208052</span></span>
<span><span class="co">#&gt; x_003 0.8106106 .       </span></span>
<span><span class="co">#&gt; x_004 .         .       </span></span>
<span><span class="co">#&gt; x_005 .         2.302190</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $derivatives</span></span>
<span><span class="co">#&gt; # A tibble: 1,200 × 2</span></span>
<span><span class="co">#&gt;       d1    d2</span></span>
<span><span class="co">#&gt;    &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span><span class="co">#&gt;  1 0.973 0.385</span></span>
<span><span class="co">#&gt;  2 1.41  0.550</span></span>
<span><span class="co">#&gt;  3 4.06  0.190</span></span>
<span><span class="co">#&gt;  4 1.74  0.461</span></span>
<span><span class="co">#&gt;  5 1.62  0.603</span></span>
<span><span class="co">#&gt;  6 4.04  0.159</span></span>
<span><span class="co">#&gt;  7 2.60  0.389</span></span>
<span><span class="co">#&gt;  8 1.90  0.599</span></span>
<span><span class="co">#&gt;  9 2.89  0.386</span></span>
<span><span class="co">#&gt; 10 0.777 0.374</span></span>
<span><span class="co">#&gt; # ℹ 1,190 more rows</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $var_y</span></span>
<span><span class="co">#&gt; [1] "y"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_index</span></span>
<span><span class="co">#&gt; [1] "x_000" "x_001" "x_002" "x_003" "x_004" "x_005"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_s</span></span>
<span><span class="co">#&gt; NULL</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $vars_linear</span></span>
<span><span class="co">#&gt; NULL</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $neighbour</span></span>
<span><span class="co">#&gt; [1] 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $gam</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: gaussian </span></span>
<span><span class="co">#&gt; Link function: identity </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(index1, bs = "cr") + s(index2, bs = "cr")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Estimated degrees of freedom:</span></span>
<span><span class="co">#&gt; 8.50 6.08  total = 15.58 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; REML score: -1028.858     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"class")</span></span>
<span><span class="co">#&gt; [1] "smimodelFit" "list"</span></span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Selected penalty parameter combination</span></span>
<span><span class="va">smimodel_ppr_tune</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">best_lambdas</span></span>
<span><span class="co">#&gt; [1] 0.01489049 0.01000000</span></span></code></pre></div>
<p>Here the selected penalty parameter combination is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>λ</mi><mn>0</mn></msub><mo>,</mo><msub><mi>λ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>0.01489049</mn><mo>,</mo><mn>0.01000000</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(\lambda_{0}, \lambda_{2}) = (0.01489049, 0.01000000)</annotation></semantics></math>.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Nuwani Palihawadana.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
